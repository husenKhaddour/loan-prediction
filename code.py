# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tRweHbcRWZkdJIM-WIv-9lSlEqMHdBcf

## Data loading and Exploring | تحميل مجوعة البيانات واستكشافها
"""

# تحميل المكتبات المطلوبة
import seaborn as sns
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn import metrics
import pickle
from sklearn.tree import export_graphviz
from io import StringIO

from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score


from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import KBinsDiscretizer
from sklearn.preprocessing import LabelEncoder

from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

import warnings
warnings.filterwarnings('ignore')
from IPython.display import Image
import pydotplus

# قراءة مجموعة البيانات
df =pd.read_csv('loan_prediction.csv')

#عرض أو خمسة أسطر من المجمووعة
df.head(5)

# إعادة تسمية الأعمدة لسهولة القراءة
columns =['#','LoanID', 'Gender', 'Married', 'Dependents', 'Education',
       'SelfEmployed', 'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount',
       'LoanAmountTerm', 'CreditHistory', 'PropertyArea', 'target']
df.columns= columns

# عرض حجم مجموعة البيانات
# حيث كما نلاحظ فهيا تتكزن من 614 سجل وكل سجيل يتكون من أربعة عشرة سطراً

print(f'the shape of the data frame is {df.shape } , rows : {df.shape[0]} , columns : {df.shape[1]}\n\n')

# عرض بعض المعلومات عن المجموعة
print(f'the information of the data frame is ')

df.info()

# نلاحظ أن هنالك عمودين ها معرف القرض وقم السطر اليقدمان أي معلومة مفيدة
# لذلك سنقوم بإزالتهما من المجموعة
df = df.drop(['LoanID','#'],axis = 1)

# عرض مقدار القيم الفارغة أي غير الموجودة
# ونلاحظ أن عددها قليل نسبيا لذللك يمكننا حذفها
# كما يمكننا تبدييلها باأكثر تكراراً وهو ماسنفعله
df.isnull().sum()

# استبدال القيم الفارغة بالقيمة الأكثر تكراراً من أجل الأعمدة الفئوية
df['Gender'].fillna(df['Gender'].mode()[0], inplace=True)
df['Married'].fillna(df['Married'].mode()[0], inplace=True)
df['Dependents'].fillna(df['Dependents'].mode()[0], inplace=True)
df['SelfEmployed'].fillna(df['SelfEmployed'].mode()[0], inplace=True)
df['CreditHistory'].fillna(df['CreditHistory'].mode()[0], inplace=True)
df['LoanAmountTerm'].fillna(df['LoanAmountTerm'].mode()[0], inplace=True)

# اسبتدال القيمة الفارغة بالمنوسط من أجل الأعمدة العددية
df['LoanAmount'].fillna(df['LoanAmount'].mean(), inplace=True)

# نلاحط أن جميع القيم الفارغة أزيلت
df.isnull().sum()

# للحقول العددية وصف مجموعة البيانات
#
df.describe()

# تعريف الأعمدة العددية والفئوية
# لقد عرفنا العمود
#على أنه فوي لأن له ثلاث قيم عددية فقط loan amount term

numerical_columns = [  'ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']

categorical_columns = [ 'Gender', 'Married', 'Dependents', 'Education', 'LoanAmountTerm',
                        'SelfEmployed', 'CreditHistory', 'PropertyArea' ]

# رسم مصفوفة اترابط بين الحقول العدددية
# نلاحظ أن هناط ارتباط بين مقدار القررض ودخل المتقدم
numeric_columns = df[numerical_columns]
plt.figure(figsize=(10,7))
sns.heatmap(numeric_columns.corr(), annot=True, cmap='inferno')

# ترميز الأعمدة الفئوية
# أي تويللها من نصوص إلى أرقام مثل
# (Y,N) => (1,0)
# تعريف المرمز الذي سوف نستخدمه للترميز
label_encoder = LabelEncoder()
for column in categorical_columns:
    # تطبيق الترميز
    df[column] = label_encoder.fit_transform(df[column])

# ترميز العمود الهدف من
# إلى0 و 1 y,n
df.target = df.target.map({'Y': 1 , 'N':0})

# إزالة القم الشائة
# وهي التي تقع خارج الربعين
for feature in numerical_columns:
    # ترعيف الربع الأدنى والربع الأعلى
    Q1 = df[feature].quantile(0.25)
    Q3 = df[feature].quantile(0.75)
    # تعريف النطاق
    IQR = Q3 - Q1
    # تعريف الحدود
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    # حذف القيم الخارجة
    df = df[(df[feature] >= lower_bound) & (df[feature] <= upper_bound)]

# رسم مخطط توزع القيم
plt.figure(figsize=(10, 7))
for i, column in enumerate(numerical_columns, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(x=df[column])

# مخطط توزع القيم ولكن كمنحن

sns.set(style="darkgrid")
fig, axs = plt.subplots(2, 2, figsize=(10, 8))

sns.histplot(data=df, x="CoapplicantIncome", kde=True, ax=axs[1, 0], color='skyblue')
sns.histplot(data=df, x="LoanAmount", kde=True, ax=axs[0, 1], color='orange')

sns.histplot(data=df, x="ApplicantIncome", kde=True, ax=axs[0, 0], color='green')
sns.histplot(data=df, x="LoanAmountTerm", kde=True, ax=axs[1, 1], color='orange')

# تنظيم البيانات وإعادتها إلى المجال 0 1 من إجل القيم العددية لان بعض النماذج تتحسس لتوزع المجال
scaled_columns = ['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']
standard_scaler = StandardScaler()
df[scaled_columns] = standard_scaler.fit_transform(df[scaled_columns])

# مخططط التوزع بعد تنظيم البياناتplt.figure(figsize=(10, 7))
for i, column in enumerate(scaled_columns, 1):
    plt.subplot(2, 2, i)
    sns.boxplot(x=df[column])

# مخطط توزع القيم الفئوية
plt.figure(figsize=(10, 7))
for i, column in enumerate(categorical_columns, 1):
    plt.subplot(3, 3, i)
    sns.countplot(x=df[column])

# مخطط توزع القيم الفئوية مع أخذ النتيجة بالاعتبار

figure ,axes = plt.subplots(4,2,figsize=(10,15))
for index,categorical_col in enumerate(categorical_columns):
    row,col = index//2,index%2
    sns.countplot(x=categorical_col,data=df,hue='target',ax=axes[row,col])

# عرض مجموعة البيانات بعد تلك المعالجات
df.head(5)

"""## تحضير المجموعة للتدريب"""

# تحضير البيانات للتدريب
X=df.drop('target',axis=1)
Y=df['target']

# KBinsDiscretizer تحويل القيم العددية إل فئوية باستخدام التابع

numerical_colmns_cat =['ApplicantIncomeCat', 'CoapplicantIncomeCat', 'LoanAmountCat']
# تعريف التابع
discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal',strategy='kmeans')

# تطبيق التابع
X[numerical_colmns_cat] = discretizer.fit_transform(X[numerical_columns])

# تقسيم المجموعة إلى تدريب واختبار
X_train ,X_test,y_train , y_test =train_test_split(X,Y,test_size=0.3,random_state=47)

"""## استخدام نموذج أشجار القرار"""

# تعريف موسطات البحث
parameters = {
    # أكبر عمق للشجرة
    'max_depth': [8,10,15,13,15],
    # أقل عدد عناصر لتقسيم العقدة
    'min_samples_split': [35,45,50,60],
    # أقل عدد عناصر لاعتبار عقدة ورقة
    'min_samples_leaf': [20,30,25,35],
    # معيار تقويم الشجرة
    'criterion': [ 'entropy']
}

DT_grid_search = GridSearchCV(DecisionTreeClassifier(criterion='entropy'), parameters,scoring='f1', cv=5)

# تدريب الشجرة
DT_grid_search.fit(X_train[numerical_colmns_cat+ categorical_columns], y_train)

# عرض موسطات النوذج الأفضل
print(f'Best parameters: {DT_grid_search.best_params_}')

DT_y_pred = DT_grid_search.best_estimator_.predict(X_test[numerical_colmns_cat+ categorical_columns])

# تقييم النموذج على مجموعة الاختبار
accuracy = accuracy_score(y_test, DT_y_pred)
print(f'Accuracy of DecisionTreeClassifier after scaling: {accuracy}')

# عرض مصفوفة التقييم

cm=  confusion_matrix(DT_y_pred,y_test)
cm_matrix = pd.DataFrame(data=cm,columns=['Actual negative :0','Actual positive :1']
                         ,index=['Predict positive :0','Predict pnegative :1'])
sns.heatmap(cm_matrix,annot=True,fmt='d',cmap='YlGnBu')

DT_y_pred = DT_grid_search.best_estimator_.predict(X_test[numerical_colmns_cat+ categorical_columns])

# تقييم النموذج

# الصحة
accuracy = accuracy_score(y_test, DT_y_pred)
# الدقة
precision = precision_score(y_test, DT_y_pred)
# تقرير التصنيف
print(classification_report(y_test, DT_y_pred))

# رسم الشجرة
dot_data = StringIO()
export_graphviz(DT_grid_search.best_estimator_, out_file=dot_data,
                filled=True, rounded=True,
                special_characters=True,feature_names = numerical_colmns_cat+categorical_columns ,class_names=['not elligable','elligalbe'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_png('loan9.png')
Image(graph.create_png())

"""## SVM استخدام نموذج"""

# تعريف المصنف
svc = SVC ()

# تعريف موسطات البحث
parameters = [
    {'C': range(1,100,10),'kernel':['linear']}
   ]
#
SVM_grid_search = GridSearchCV(estimator=svc,
                          param_grid=parameters,
                          scoring="f1",
                          cv=5,
                          verbose=1)

# تدريب النوذج
SVM_grid_search.fit(X_train[numerical_columns+ categorical_columns], y_train)

svm_best=SVM_grid_search.best_estimator_

print(f'Best parameters: {svm_best}')

SVM_y_pred = svm_best.predict(X_test[numerical_columns+ categorical_columns])

# تقييم النموذج
accuracy = accuracy_score(y_test, SVM_y_pred)

# عرض حة النموذج
print(f'Accuracy of SVM after scaling: {accuracy}')

# تقرير التصنيف
print(classification_report(y_test, SVM_y_pred))

# عرض مصفوفة التقييم
cm=  confusion_matrix(SVM_y_pred,y_test)
cm_matrix = pd.DataFrame(data=cm,columns=['Actual negative :0','Actual positive :1']
                         ,index=['Predict positive :0','Predict pnegative :1'])
sns.heatmap(cm_matrix,annot=True,fmt='d',cmap='YlGnBu')

"""## KNN استخدام نموذج أقرب جار"""

# تعريف موسطات البحث
parameters={'n_neighbors':range(1,40),
            'metric':['euclidean','manhattan','cosine'],
            'weights':['uniform','distance']
           }
# تعريف النموذج
KNN_=KNeighborsClassifier()
# تعريق البحث
KNN_grid_search=GridSearchCV(estimator=KNN_,param_grid=parameters,cv=5,scoring="f1")

# تدريب النموذج
KNN_grid_search.fit(X_train[numerical_columns+ categorical_columns],y_train)
# عرض موسطات النوذج الأفضل
print(KNN_grid_search.best_params_)

knn_y_pred = KNN_grid_search.best_estimator_.predict(X_test[numerical_columns+ categorical_columns])

# تقييم النموذج
accuracy = accuracy_score(y_test, knn_y_pred)

# عرض حة النموذج
print(f'Accuracy of SVM after scaling: {accuracy}')

# تقرير التصنيف
print(classification_report(y_test, knn_y_pred))

# عرض مصفوفة التقييم
cm=  confusion_matrix(knn_y_pred,y_test)
cm_matrix = pd.DataFrame(data=cm,columns=['Actual negative :0','Actual positive :1']
                         ,index=['Predict positive :0','Predict pnegative :1'])
sns.heatmap(cm_matrix,annot=True,fmt='d',cmap='YlGnBu')

"""## حفظ مجموعة البيانات بعد معالجتها والنماذج"""

# حفظ مجموعة البيانات
df.to_csv('cleaned-loan.csv',index=False)

# حفظ النماذج

pickle.dump(DT_grid_search.best_estimator_,open('loan_dt.pkl','wb'))
pickle.dump(svm_best,open('loan_svm.pkl','wb'))
pickle.dump(KNN_grid_search.best_estimator_,open('loan_knn.pkl','wb'))

# والترميز  normalisation حفظ عمليةال
pickle.dump(label_encoder,open('label_encoder.pkl','wb'))
pickle.dump(standard_scaler,open('standard_scaler.pkl','wb'))

